# RouteIQ v0.1.0 Design Document

**Date:** 2026-02-13
**Version:** 0.0.5 -> 0.1.0
**Approach:** Issue-Driven Waves (4 waves, each independently shippable)

## Current State

- RouteIQ v0.0.5, Python 3.14+
- LiteLLM submodule at `v1.81.3.rc.5` (latest stable: `v1.81.3-stable.opus-4-6`)
- LLMRouter submodule at `e467838` (behind `origin/main` at `6eeb646`)
- 9 open GitHub issues (2 bugs, 6 enhancements, 1 documentation)
- 18+ routing strategies registered, all core subsystems operational

## Open Issues

| # | Title | Type | Wave |
|---|-------|------|------|
| 6 | Graceful incremental config reload (OOM on Fargate) | bug/enhancement | 1 |
| 9 | Retry logic for Prisma migrations in entrypoint.sh | bug | 1 |
| 7 | `/config/status` endpoint for S3 sync observability | enhancement | 2 |
| 8 | Per-model circuit breaker state in `/_health/ready` | enhancement | 2 |
| 12 | Configurable CORS origins | enhancement | 2 |
| 13 | Configurable OTEL metrics namespace | enhancement | 2 |
| 11 | Multi-account Bedrock model discovery | enhancement | 4 |
| 10 | Document CloudFront/ALB streaming settings | documentation | 4 |
| 1 | Cloudflare skills discovery | enhancement | 4 |

## Upstream Gaps

### LiteLLM v1.81.x Features Not Yet in RouteIQ

- New model providers (gpt-5.2-codex, Cerebras, Replicate)
- MCP auth header propagation
- A2A improvements (Pydantic AI agents, Vertex AI Agent Engine)
- Built-in content filter guardrails + image filtering
- Guardrails load balancing
- K8s ServiceAccount JWT auth
- Lazy loading for performance
- Azure Model Router

### LLMRouter Upstream Changes

- ComfyUI integration (latest `origin/main` commits)
- `feature/clawbot-router` branch (new router type in development)
- `feature/rename-to-openclaw-router` branch (potential rebranding)

---

## Wave 1: Foundation

**Goal:** Production stability. Update submodules, fix the two critical bugs.

### 1.1 Submodule Updates

**LiteLLM**: `reference/litellm` from `v1.81.3.rc.5` -> `v1.81.3-stable.opus-4-6`
- PyPI pin stays `litellm>=1.81.3,<1.82.0` (already correct range)
- Verify no breaking API changes between rc5 and stable
- Run full unit test suite after update

**LLMRouter**: `reference/LLMRouter` from `e467838` -> `6eeb646` (latest `origin/main`)
- Latest commits are README/ComfyUI updates (low risk)
- No API-breaking changes detected

### 1.2 Issue #6: Graceful Incremental Config Reload

**Problem:** Config reload re-initializes all model clients simultaneously, causing OOM on
Fargate (512MB-2GB task memory). Every reload risks container restart (exit code 129).

**Solution:** Incremental reload with atomic swap:

1. Parse new config, diff against current config
2. Identify added/removed/changed model entries
3. Tear down removed/changed model clients first (free memory)
4. Initialize new/changed model clients one at a time
5. Atomic swap of active router once all clients ready
6. Rollback to old config if any client init fails, report error

**Files:**
- `hot_reload.py` -- add config diffing logic
- `config_sync.py` -- incremental client lifecycle
- `gateway/app.py` -- atomic router swap

**Config:**
- `CONFIG_RELOAD_INCREMENTAL=true` (default, new behavior)
- `CONFIG_RELOAD_ROLLBACK=true` (default, auto-rollback on failure)

**Testing:**
- Unit test: config diff produces correct add/remove/change sets
- Unit test: rollback triggers when client init raises
- Integration test: reload with 10+ models stays under 512MB peak

### 1.3 Issue #9: Prisma Migration Retry

**Problem:** `prisma db push` in `entrypoint.sh` fails on Aurora cold starts, causing
ECS crash loops until the database becomes available.

**Solution:** Exponential backoff retry in `docker/entrypoint.sh`:

```bash
MAX_RETRIES=${DB_MIGRATION_MAX_RETRIES:-10}
RETRY_DELAY=${DB_MIGRATION_RETRY_DELAY:-5}

for i in $(seq 1 $MAX_RETRIES); do
    echo "Attempting database migration (attempt $i/$MAX_RETRIES)..."
    if prisma db push --accept-data-loss 2>&1; then
        echo "Database migration successful."
        break
    fi
    if [ $i -eq $MAX_RETRIES ]; then
        echo "ERROR: Database migration failed after $MAX_RETRIES attempts."
        exit 1
    fi
    SLEEP_TIME=$((RETRY_DELAY * i))
    echo "Migration failed. Retrying in ${SLEEP_TIME}s..."
    sleep $SLEEP_TIME
done
```

**Environment Variables:**

| Variable | Default | Description |
|----------|---------|-------------|
| `DB_MIGRATION_MAX_RETRIES` | `10` | Max migration attempts |
| `DB_MIGRATION_RETRY_DELAY` | `5` | Base delay (multiplied by attempt number) |
| `DB_MIGRATION_SKIP` | `false` | Skip migrations entirely (for replicas) |

**Testing:**
- Manual test against Aurora PostgreSQL with simulated delayed availability
- Verify `DB_MIGRATION_SKIP=true` bypasses the loop entirely

---

## Wave 2: Observability & Operations

**Goal:** Close operational visibility gaps. Make RouteIQ production-observable.

### 2.1 Issue #7: `/config/status` Endpoint

**New endpoint:** `GET /config/status` (unauthenticated, same access as health checks)

```json
{
  "config_source": "s3://bucket-name/config/config.yaml",
  "sync_enabled": true,
  "sync_interval_seconds": 60,
  "last_sync_attempt": "2026-02-13T10:30:00Z",
  "last_sync_success": "2026-02-13T10:30:00Z",
  "last_sync_error": null,
  "config_version_hash": "sha256:abc123...",
  "model_count": 12,
  "next_sync_at": "2026-02-13T10:31:00Z"
}
```

**OTel Metric:** `routeiq.config.sync.age_seconds` (gauge)

**Files:**
- `routes/config.py` -- new `/config/status` route
- `config_sync.py` -- track sync timestamps and errors
- `observability.py` -- emit sync age metric

**Testing:**
- Unit test: endpoint returns correct shape
- Unit test: `last_sync_error` populated on failure
- Unit test: `config_version_hash` changes when config changes

### 2.2 Issue #8: Per-Model Circuit Breaker Health

**Extended `/_health/ready`:**

```json
{
  "status": "healthy",
  "models": { "healthy": 10, "degraded": 1, "unhealthy": 1, "total": 12 }
}
```

**New `GET /_health/models`:**

```json
{
  "models": [
    {
      "model_id": "bedrock/us-east-1/anthropic.claude-sonnet-4-20250514-v1:0",
      "status": "healthy",
      "circuit_breaker": "closed",
      "last_success": "2026-02-13T10:29:55Z",
      "error_rate_1m": 0.0,
      "latency_p50_ms": 450
    }
  ]
}
```

**Config:** `HEALTH_MIN_MODELS=1` (minimum healthy models before `/_health/ready` returns 503)

**Files:**
- `routes/health.py` -- extend ready endpoint, add models endpoint
- `resilience.py` -- expose circuit breaker state via public API

**Testing:**
- Unit test: healthy/degraded/unhealthy counts
- Unit test: 503 when below HEALTH_MIN_MODELS threshold
- Unit test: per-model detail includes all fields

### 2.3 Issue #12: Configurable CORS

**Environment Variables:**

| Variable | Default | Description |
|----------|---------|-------------|
| `ROUTEIQ_CORS_ORIGINS` | `*` | Comma-separated allowed origins |
| `ROUTEIQ_CORS_CREDENTIALS` | `false` | Allow credentials |

**Files:**
- `gateway/app.py` -- parse env vars, configure CORSMiddleware

**Testing:**
- Unit test: origins parsed correctly from comma-separated string
- Unit test: credentials flag applied

### 2.4 Issue #13: Configurable OTEL Namespace

**Environment Variables:**

| Variable | Default | Description |
|----------|---------|-------------|
| `ROUTEIQ_METRICS_NAMESPACE` | `RouteIQ` | CloudWatch metrics namespace |
| `ROUTEIQ_SERVICE_NAME` | `routeiq` | OTEL service name |
| `ROUTEIQ_DEPLOYMENT_ENV` | `default` | Environment tag |

**Files:**
- `observability.py` -- use env vars in OTel initialization

**Testing:**
- Unit test: namespace applied to metric names
- Unit test: service name in resource attributes
- Unit test: environment tag in resource attributes

### 2.5 LiteLLM Feature Parity

**New Providers:**
- gpt-5.2-codex, Cerebras, Replicate come free with LiteLLM dependency update
- Add config examples in `config/examples/`
- Add integration test skeletons (skip without API keys)

**Built-in Guardrails:**
- Integrate LiteLLM content filter guardrails
- Image content filtering support
- Guardrails load balancing
- Document guardrails configuration in README

**MCP Auth Header Propagation:**
- Verify RouteIQ's MCP surfaces forward auth headers correctly
- Add test for `Authorization` header propagation through MCP proxy

**K8s ServiceAccount JWT Auth:**
- Add K8s JWT validation in `auth.py`
- Config: `AUTH_K8S_ENABLED=false`, `AUTH_K8S_ISSUER`
- Useful for EKS deployments without API key management

---

## Wave 3: Routing Intelligence

**Goal:** Ensure all routing strategies work with latest upstream, improve telemetry,
document custom router plugin system.

### 3.1 Strategy Integration Audit

RouteIQ registers all 18 LLMRouter strategies in `strategies.py`. Work needed:

1. **Runtime compatibility test** with latest LLMRouter `origin/main`
   - Ensure `LLMRouterStrategyFamily` handles any API changes
   - Test each strategy can be instantiated with default hyperparameters
2. **Integration tests** for newer strategies:
   - GraphRouter (requires PyTorch Geometric)
   - DCRouter (dual contrastive)
   - CausalLMRouter (requires model weights)
   - Multi-round routers (KNNMultiRound, LLMMultiRound)
   - GMTRouter (graph-based personalized)
   - AutomixRouter (self-verification)
3. **Monitor upstream branches:**
   - `feature/clawbot-router` -- potential new router type
   - `feature/rename-to-openclaw-router` -- potential rebranding

### 3.2 Strategy Telemetry Improvements

- Emit structured OTel spans per routing decision:
  - Strategy name, model selected, confidence score, decision latency
  - Fallback chain (if primary strategy fails)
- `GET /llmrouter/strategies/compare` endpoint:
  - Win rates across active strategies
  - Cost savings vs. quality trade-offs
  - Decision latency percentiles

**Files:**
- `router_decision_callback.py` -- enhanced span attributes
- `strategy_registry.py` -- comparison data collection
- `routes/` -- new comparison endpoint

### 3.3 Cost-Aware Routing Enhancements

- Update `model_prices_and_context_window.json` from LiteLLM v1.81.x
- Emit `routeiq.routing.cost_per_1k_tokens` metric
- Validate circuit breaker filtering integration end-to-end

### 3.4 Custom Router Plugin Documentation

Document the `llmrouter-custom` strategy:
- `CustomRouter` base class interface
- Config-driven loading: `routing_strategy: llmrouter-custom:my_module.MyRouter`
- Example custom router in `custom_routers/example_router.py`
- Testing guide for custom routers

---

## Wave 4: Cloud-Native Extensions

**Goal:** Model discovery, protocol extensions, documentation, version bump.

### 4.1 Issue #11: Multi-Account Bedrock Model Discovery

**New module:** `discovery.py`

**Config schema:**

```yaml
discovery:
  enabled: true
  interval_seconds: 3600
  providers:
    - type: bedrock
      accounts:
        - account_id: "111111111111"
          role_arn: "arn:aws:iam::111111111111:role/LLMModelAccessRole"
          regions: ["us-east-1", "us-west-2"]
    - type: sagemaker
      accounts:
        - account_id: "111111111111"
          role_arn: "arn:aws:iam::111111111111:role/LLMModelAccessRole"
          endpoint_prefix: "llm-"
```

**Endpoints:**
- `GET /models/discover` -- list discovered models across accounts
- `GET /models/diff` -- diff discovered vs. configured models
- `POST /models/sync` -- apply discovered models to config (admin auth required)

**Files:**
- New `discovery.py` module
- New route in `routes/models.py`
- Config schema extension in `config_loader.py`

**Testing:**
- Unit test with mocked STS/Bedrock/SageMaker clients
- Integration test with real AWS accounts (requires credentials, auto-skip)

### 4.2 Issue #1: Cloudflare Skills Discovery (A2A/MCP)

Implement the Cloudflare Agent Skills Discovery RFC:

- `GET /.well-known/agent.json` endpoint
- Advertise available models, routing strategies, MCP tools
- Integrate with A2A gateway (`a2a_gateway.py`)
- Auto-generate from current config

**Files:**
- New route in `routes/` or `a2a_gateway.py`
- JSON schema based on Cloudflare RFC

### 4.3 Issue #10: CloudFront/ALB Documentation

Create `docs/deployment/cloudfront-alb.md`:
- ALB settings (idle timeout 300s, deregistration delay 120s)
- CloudFront settings (origin read timeout, cache policy, origin request policy)
- Required SSE response headers
- Authorization header caveat (restricted header, must use allViewer)
- CDK snippet examples

### 4.4 Plugin System Documentation

- `docs/plugins/writing-a-plugin.md` -- getting started guide
- `docs/plugins/api-reference.md` -- GatewayPlugin interface
- Plugin dependency resolution telemetry
- Example plugins in `examples/plugins/`

### 4.5 Version Bump

- `pyproject.toml`: `version = "0.1.0"`
- Update CHANGELOG.md
- Tag release

---

## Cross-Cutting Concerns

### Testing Strategy

- Each wave adds its own unit tests
- Integration tests require Docker stack (`docker-compose.local-test.yml`)
- Property-based tests (hypothesis) for config diffing logic
- All existing tests must pass after submodule updates

### Migration Path

- No breaking API changes for existing users
- New env vars all have backwards-compatible defaults
- Config format is additive (new `discovery:` block is optional)

### Risk Mitigation

| Risk | Mitigation |
|------|-----------|
| LiteLLM stable tag has regressions | Run full test suite before merging Wave 1 |
| LLMRouter API changes break strategies | Integration tests per strategy |
| Incremental reload introduces race conditions | Atomic swap + mutex on router instance |
| Discovery module leaks AWS credentials | STS temp credentials, no caching of secrets |

---

## Branch Strategy

Each wave gets its own branch following the TG pattern:

- `tg-v010-wave1-foundation`
- `tg-v010-wave2-observability`
- `tg-v010-wave3-routing`
- `tg-v010-wave4-cloud-native`

Squash merge each to `main` when complete.
